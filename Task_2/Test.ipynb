{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "https://matheuscammarosanohidalgo.medium.com/a-very-simple-variational-quantum-classifier-vqc-64e8ec26589d\n",
    "tutaj dodają jakieś dane"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train: Values: [-1.  1.] Counts: [40 40]\n",
      "Y_val: Values: [-1.  1.] Counts: [4 6]\n",
      "Y_test: Values: [-1.  1.] Counts: [6 4]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Features must be of length 16; got length 4. Use the 'pad_with' argument for automated padding.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 12\u001B[0m\n\u001B[0;32m      9\u001B[0m shape \u001B[38;5;241m=\u001B[39m qml\u001B[38;5;241m.\u001B[39mStronglyEntanglingLayers\u001B[38;5;241m.\u001B[39mshape(n_layers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, n_wires\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     11\u001B[0m weights \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandom(size\u001B[38;5;241m=\u001B[39mshape)\n\u001B[1;32m---> 12\u001B[0m current_cost \u001B[38;5;241m=\u001B[39m \u001B[43mcost\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Projects_All\\QML-for-Conspicuity-Detection-in-Production\\Task_2\\modules\\Circuit_centric_ansatz.py:24\u001B[0m, in \u001B[0;36mcost\u001B[1;34m(weights, bias, X, Y)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcost\u001B[39m(weights, bias, X, Y):\n\u001B[1;32m---> 24\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m [variational_classifier(weights, bias, x) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m X]\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m square_loss(Y, predictions)\n",
      "File \u001B[1;32m~\\Projects_All\\QML-for-Conspicuity-Detection-in-Production\\Task_2\\modules\\Circuit_centric_ansatz.py:24\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcost\u001B[39m(weights, bias, X, Y):\n\u001B[1;32m---> 24\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m [\u001B[43mvariational_classifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m X]\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m square_loss(Y, predictions)\n",
      "File \u001B[1;32m~\\Projects_All\\QML-for-Conspicuity-Detection-in-Production\\Task_2\\modules\\Circuit_centric_ansatz.py:14\u001B[0m, in \u001B[0;36mvariational_classifier\u001B[1;34m(weights, bias, x)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvariational_classifier\u001B[39m(weights, bias, x):\n\u001B[1;32m---> 14\u001B[0m     pi \u001B[38;5;241m=\u001B[39m (\u001B[43mcircuit_centric\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m  pi \u001B[38;5;241m+\u001B[39m bias\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Womanium_Project\\lib\\site-packages\\pennylane\\workflow\\qnode.py:1164\u001B[0m, in \u001B[0;36mQNode.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1162\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m qml\u001B[38;5;241m.\u001B[39mcapture\u001B[38;5;241m.\u001B[39menabled():\n\u001B[0;32m   1163\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m qml\u001B[38;5;241m.\u001B[39mcapture\u001B[38;5;241m.\u001B[39mqnode_call(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1164\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_impl_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Womanium_Project\\lib\\site-packages\\pennylane\\workflow\\qnode.py:1144\u001B[0m, in \u001B[0;36mQNode._impl_call\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1141\u001B[0m     override_shots \u001B[38;5;241m=\u001B[39m kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshots\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1143\u001B[0m \u001B[38;5;66;03m# construct the tape\u001B[39;00m\n\u001B[1;32m-> 1144\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstruct\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1146\u001B[0m original_grad_fn \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgradient_fn, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgradient_kwargs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice]\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_gradient_fn(shots\u001B[38;5;241m=\u001B[39moverride_shots, tape\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tape)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Womanium_Project\\lib\\site-packages\\pennylane\\logging\\decorators.py:61\u001B[0m, in \u001B[0;36mlog_string_debug_func.<locals>.wrapper_entry\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     54\u001B[0m     s_caller \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m::L\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[0;32m     55\u001B[0m         [\u001B[38;5;28mstr\u001B[39m(i) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39mgetouterframes(inspect\u001B[38;5;241m.\u001B[39mcurrentframe(), \u001B[38;5;241m2\u001B[39m)[\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m1\u001B[39m:\u001B[38;5;241m3\u001B[39m]]\n\u001B[0;32m     56\u001B[0m     )\n\u001B[0;32m     57\u001B[0m     lgr\u001B[38;5;241m.\u001B[39mdebug(\n\u001B[0;32m     58\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCalling \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mf_string\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m from \u001B[39m\u001B[38;5;132;01m{\u001B[39;00ms_caller\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     59\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_debug_log_kwargs,\n\u001B[0;32m     60\u001B[0m     )\n\u001B[1;32m---> 61\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Womanium_Project\\lib\\site-packages\\pennylane\\workflow\\qnode.py:966\u001B[0m, in \u001B[0;36mQNode.construct\u001B[1;34m(self, args, kwargs)\u001B[0m\n\u001B[0;32m    964\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m pldb_device_manager(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice):\n\u001B[0;32m    965\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m qml\u001B[38;5;241m.\u001B[39mqueuing\u001B[38;5;241m.\u001B[39mAnnotatedQueue() \u001B[38;5;28;01mas\u001B[39;00m q:\n\u001B[1;32m--> 966\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_qfunc_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    968\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tape \u001B[38;5;241m=\u001B[39m QuantumScript\u001B[38;5;241m.\u001B[39mfrom_queue(q, shots)\n\u001B[0;32m    970\u001B[0m params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtape\u001B[38;5;241m.\u001B[39mget_parameters(trainable_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32m~\\Projects_All\\QML-for-Conspicuity-Detection-in-Production\\Task_2\\modules\\Circuit_centric_ansatz.py:8\u001B[0m, in \u001B[0;36mcircuit_centric\u001B[1;34m(weights, x, num_qubits)\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;129m@qml\u001B[39m\u001B[38;5;241m.\u001B[39mqnode(dev)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcircuit_centric\u001B[39m(weights, x, num_qubits\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m):\n\u001B[0;32m      7\u001B[0m     wires \u001B[38;5;241m=\u001B[39m [i \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_qubits)]\n\u001B[1;32m----> 8\u001B[0m     \u001B[43mqml\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAmplitudeEmbedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwires\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwires\u001B[49m\u001B[43m,\u001B[49m\u001B[43mnormalize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m     qml\u001B[38;5;241m.\u001B[39mStronglyEntanglingLayers(weights\u001B[38;5;241m=\u001B[39mweights, wires\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m4\u001B[39m))\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m qml\u001B[38;5;241m.\u001B[39mexpval(qml\u001B[38;5;241m.\u001B[39mZ(\u001B[38;5;241m0\u001B[39m))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Womanium_Project\\lib\\site-packages\\pennylane\\capture\\capture_meta.py:89\u001B[0m, in \u001B[0;36mCaptureMeta.__call__\u001B[1;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[0;32m     85\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m enabled():\n\u001B[0;32m     86\u001B[0m     \u001B[38;5;66;03m# when tracing is enabled, we want to\u001B[39;00m\n\u001B[0;32m     87\u001B[0m     \u001B[38;5;66;03m# use bind to construct the class if we want class construction to add it to the jaxpr\u001B[39;00m\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_primitive_bind_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 89\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtype\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Womanium_Project\\lib\\site-packages\\pennylane\\templates\\embeddings\\amplitude.py:125\u001B[0m, in \u001B[0;36mAmplitudeEmbedding.__init__\u001B[1;34m(self, features, wires, pad_with, normalize, id)\u001B[0m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpad_with \u001B[38;5;241m=\u001B[39m pad_with\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnormalize \u001B[38;5;241m=\u001B[39m normalize\n\u001B[1;32m--> 125\u001B[0m features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_preprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwires\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpad_with\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormalize\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    126\u001B[0m \u001B[38;5;28msuper\u001B[39m(StatePrep, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(features, wires\u001B[38;5;241m=\u001B[39mwires, \u001B[38;5;28mid\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mid\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Womanium_Project\\lib\\site-packages\\pennylane\\templates\\embeddings\\amplitude.py:179\u001B[0m, in \u001B[0;36mAmplitudeEmbedding._preprocess\u001B[1;34m(features, wires, pad_with, normalize)\u001B[0m\n\u001B[0;32m    177\u001B[0m dim \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(wires)\n\u001B[0;32m    178\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pad_with \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m n_features \u001B[38;5;241m!=\u001B[39m dim:\n\u001B[1;32m--> 179\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    180\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFeatures must be of length \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdim\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m; got length \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_features\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    181\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUse the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpad_with\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m argument for automated padding.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    182\u001B[0m     )\n\u001B[0;32m    184\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pad_with \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    185\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_features \u001B[38;5;241m>\u001B[39m dim:\n",
      "\u001B[1;31mValueError\u001B[0m: Features must be of length 16; got length 4. Use the 'pad_with' argument for automated padding."
     ]
    }
   ],
   "source": [
    "from modules.Ansatz import circuit\n",
    "import pennylane.numpy as np\n",
    "\n",
    "def variational_classifier(weights, bias, x, num_qubits, state_prep):\n",
    "    return circuit(weights, x, num_qubits, state_prep) + bias\n",
    "\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    # We use a call to qml.math.stack to allow subtracting the arrays directly\n",
    "    return np.mean((labels - qml.math.stack(predictions)) ** 2)\n",
    "\n",
    "\n",
    "def cost(weights, bias, X, Y, num_qubits, state_prep):\n",
    "    predictions = [variational_classifier(weights, bias, x, num_qubits, state_prep) for x in X]\n",
    "    return square_loss(Y, predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [[[0.5488135  0.71518937 0.60276338]\n",
      "  [0.54488318 0.4236548  0.64589411]\n",
      "  [0.43758721 0.891773   0.96366276]\n",
      "  [0.38344152 0.79172504 0.52889492]]\n",
      "\n",
      " [[0.56804456 0.92559664 0.07103606]\n",
      "  [0.0871293  0.0202184  0.83261985]\n",
      "  [0.77815675 0.87001215 0.97861834]\n",
      "  [0.79915856 0.46147936 0.78052918]]]\n",
      "Bias:  0.1\n",
      "Iter:    1 | Cost: 9.1710255 | Accuracy: 0.5937500\n",
      "Iter:    2 | Cost: 5669.6905856 | Accuracy: 0.5625000\n",
      "Iter:    3 | Cost: 4771629.1461842 | Accuracy: 0.3125000\n",
      "Iter:    4 | Cost: 3999450527.9809947 | Accuracy: 0.5625000\n",
      "Iter:    5 | Cost: 3355704034895.1791992 | Accuracy: 0.4062500\n",
      "Iter:    6 | Cost: 2815544254929149.0000000 | Accuracy: 0.5937500\n",
      "Iter:    7 | Cost: 2362333996061953536.0000000 | Accuracy: 0.6562500\n",
      "Iter:    8 | Cost: 1982075675061019213824.0000000 | Accuracy: 0.5625000\n",
      "Iter:    9 | Cost: 1663026474962005144895488.0000000 | Accuracy: 0.6562500\n",
      "Iter:   10 | Cost: 1395333735821491778288091136.0000000 | Accuracy: 0.5937500\n",
      "Iter:   11 | Cost: 1170730751213156008692199456768.0000000 | Accuracy: 0.5937500\n",
      "Iter:   12 | Cost: 982281483382287184603132769337344.0000000 | Accuracy: 0.4062500\n",
      "Iter:   13 | Cost: 824166369249175543405664451111682048.0000000 | Accuracy: 0.5625000\n",
      "Iter:   14 | Cost: 691502604592023546382334840024560828416.0000000 | Accuracy: 0.5312500\n",
      "Iter:   15 | Cost: 580193356583059092580657231625060595269632.0000000 | Accuracy: 0.5000000\n",
      "Iter:   16 | Cost: 486801248162644705744279443694687406084063232.0000000 | Accuracy: 0.5000000\n",
      "Iter:   17 | Cost: 408442207281262729533309370251740136116957741056.0000000 | Accuracy: 0.5000000\n",
      "Iter:   18 | Cost: 342696402933321725263595579687740352412321283309568.0000000 | Accuracy: 0.6250000\n",
      "Iter:   19 | Cost: 287533517569513524569709586892670293145925944002740224.0000000 | Accuracy: 0.4687500\n",
      "Iter:   20 | Cost: 241250048200779975052745308864846872509314145065535275008.0000000 | Accuracy: 0.4062500\n",
      "Iter:   21 | Cost: 202416699968927515651687447657419503989744208214281370468352.0000000 | Accuracy: 0.4687500\n",
      "Iter:   22 | Cost: 169834247627637968454274467310409961775344487169084855999791104.0000000 | Accuracy: 0.5000000\n",
      "Iter:   23 | Cost: 142496501877925757608719125403992832541228326559644930237530112000.0000000 | Accuracy: 0.4687500\n",
      "Iter:   24 | Cost: 119559236909419220407570638239656646627206559750611518170320601088000.0000000 | Accuracy: 0.5625000\n",
      "Iter:   25 | Cost: 100314119588762718681471581850551103164198665834706852249474258926829568.0000000 | Accuracy: 0.3437500\n",
      "Iter:   26 | Cost: 84166835193942461131640139711235884531698784410482048167936431957343207424.0000000 | Accuracy: 0.5312500\n",
      "Iter:   27 | Cost: 70618734188221081348440086369121452828105838330791574768662633488636258025472.0000000 | Accuracy: 0.4687500\n",
      "Iter:   28 | Cost: 59251433261750383649306232475823197642456914503030208419703162609939013970165760.0000000 | Accuracy: 0.4687500\n",
      "Iter:   29 | Cost: 49713895100618283332623843320534359570253881483544080660241335699354667992288854016.0000000 | Accuracy: 0.5937500\n",
      "Iter:   30 | Cost: 41711587889481965851895624735683608644329965412557314460185074118397943819121717149696.0000000 | Accuracy: 0.4687500\n",
      "Iter:   31 | Cost: 34997389778865634072028732599286747202644494539879915953617539982091027690520192623837184.0000000 | Accuracy: 0.5000000\n",
      "Iter:   32 | Cost: 29363957435020125460044213174723232736519107677917840497881695279782146992829650027872780288.0000000 | Accuracy: 0.5312500\n",
      "Iter:   33 | Cost: 24637323003053467992259915511095147629105711633371372003816617104112163143480954339704975654912.0000000 | Accuracy: 0.6250000\n",
      "Iter:   34 | Cost: 20671521749070100357744030777353012418506736962093513375641999583441582883931760902456837834539008.0000000 | Accuracy: 0.4687500\n",
      "Iter:   35 | Cost: 17344084475789758261349589344180802784234304370197791219038381264274262018900844003036328307609042944.0000000 | Accuracy: 0.5312500\n",
      "Iter:   36 | Cost: 14552255511467804362719897955093419042103804342001663001405416397631295799972905914818986044894717411328.0000000 | Accuracy: 0.3437500\n",
      "Iter:   37 | Cost: 12209819478603631054051183234397474653833827660342016021922989085245690199448860240600198016054598249218048.0000000 | Accuracy: 0.4687500\n",
      "Iter:   38 | Cost: 10244438848851122742502344530000315888455058117103069219180078473064902463787844111903302688031019615375065088.0000000 | Accuracy: 0.4062500\n",
      "Iter:   39 | Cost: 8595420064298329668409810926400971239129426336057467034008952885378030580769924989363793290967358572347969765376.0000000 | Accuracy: 0.5312500\n",
      "Iter:   40 | Cost: 7211839239982163291240493584441461569134976409159313593448283226940438708907339709655618420773327535887038107615232.0000000 | Accuracy: 0.4375000\n",
      "Iter:   41 | Cost: 6050969566848316101091305995003736432844906560706484788475962673602137320212708846160084704151666051179675367719829504.0000000 | Accuracy: 0.6250000\n",
      "Iter:   42 | Cost: 5076961851275957329577284571183537341067790908636758438951112676732546826859238810330797679962557516034984785656124801024.0000000 | Accuracy: 0.5000000\n",
      "Iter:   43 | Cost: 4259737444479790484167571959767010952784919519771719563767342258749679252561452709458852088449291356816245851697243169488896.0000000 | Accuracy: 0.5937500\n",
      "Iter:   44 | Cost: 3574059373982272684634049664729828631082091548913889919143951820118416641480384072693922987150811034238214114346714430923866112.0000000 | Accuracy: 0.4687500\n",
      "Iter:   45 | Cost: 2998752992465365134030709736956860226586676880633284468551446117969674958146982695464306441352324501188826764300878996772629774336.0000000 | Accuracy: 0.5000000\n",
      "Iter:   46 | Cost: 2516052076605653637090198178291417637409605605550508245610537812778361253521916159856255911054672623981248521382035840106680918474752.0000000 | Accuracy: 0.4687500\n",
      "Iter:   47 | Cost: 2111050182558420421036207873262238635934592470450773978056349074419435196603358546234566101381768427237006895122632776096564959485362176.0000000 | Accuracy: 0.5937500\n",
      "Iter:   48 | Cost: 1771240315221193046867130391599966497866645531000382023339124014697083510462164243800042948144389795395831812441136343546952528799631147008.0000000 | Accuracy: 0.5312500\n",
      "Iter:   49 | Cost: 1486128695653613835723709045692466369018904427245764735086040384948952211424581462481437131140002996617390444183694972585903011719809710686208.0000000 | Accuracy: 0.4062500\n",
      "Iter:   50 | Cost: 1246910699279848147856344611903981495260783145885750805225888600253369749651630823050398549008085235704932225059816100877776141306684977870536704.0000000 | Accuracy: 0.6250000\n",
      "Iter:   51 | Cost: 1046198957415829901706539773237330424689672117942942559888932739704209730175727223925057749985136414458733011511922828390652189367526023143962443776.0000000 | Accuracy: 0.3750000\n",
      "Iter:   52 | Cost: 877795225536291619276126412628544713209636263314156825877519261839551074403069134768829798001772302653675896314642904118633437497967003260698430013440.0000000 | Accuracy: 0.5000000\n",
      "Iter:   53 | Cost: 736498973271344183268401811695453552083053377834899124728636913792751066545256311222951853499679252342993245083441170635959465950383910436682528974700544.0000000 | Accuracy: 0.5000000\n",
      "Iter:   54 | Cost: 617946785138121054804201515724322278231341389566963968485049279763913725630304722383493591817287299045904780639633061959606317511835164687170928199430307840.0000000 | Accuracy: 0.5937500\n",
      "Iter:   55 | Cost: 518477612489288752139514455405653442595934278877113171670861287401885495523046497712981230835298486216997317289683056774445194838119155071488828177748932427776.0000000 | Accuracy: 0.5625000\n",
      "Iter:   56 | Cost: 435019715480044742074258744041669125762929477235684246570924208526343216932711314539501574370024117202345010040623728520595422799342883108357374877814067543670784.0000000 | Accuracy: 0.5312500\n",
      "Iter:   57 | Cost: 364995803671751367609835860008665091705463870775992269645854214387676988413985954591732434681164753929203626317865660787453830741949638365069094113170537529204539392.0000000 | Accuracy: 0.5000000\n",
      "Iter:   58 | Cost: 306243445888370925972849106951549384634535618210853426310206755892170324496534125282502779484335918790182775488649088551740793537754480381990105140890038656856735350784.0000000 | Accuracy: 0.4375000\n",
      "Iter:   59 | Cost: 256948291476596206391431082515538952649054449057993950669449068301646914512274899414339393939810021356648671257025096942528208230238062883281130426781024086594950879248384.0000000 | Accuracy: 0.3750000\n",
      "Iter:   60 | Cost: 215588040753719938846840252198364330646604320823764014773258367416762315500121885637650877973451710720026529270612187788907884026112387779826029815568255824540266493359685632.0000000 | Accuracy: 0.5937500\n",
      "Iter:   61 | Cost: 180885434376437746821454753846995826579813730478422512820323147018452478121622434909069506553753242249398919364973543301257746083490832393216280674765301001129666500441109692416.0000000 | Accuracy: 0.6562500\n",
      "Iter:   62 | Cost: 151768809879997750326396340381362690332457704526256757237033648893345353658012205544338953530051390177696689927395261443487165475453970291371692538200349187367829813682782165008384.0000000 | Accuracy: 0.5937500\n",
      "Iter:   63 | Cost: 127339007321373173257704290026556060480978907424220132853074575687422972700667283106471072513086307731642941328304169004970551241401644823518154829745096391855417875830401991490666496.0000000 | Accuracy: 0.4375000\n",
      "Iter:   64 | Cost: 106841602028861924917785017651509420822130211892000138460362898316357203178599225380408472752848530419831770876354801333403855185069445815867200152996330849044863324256769806981442568192.0000000 | Accuracy: 0.2812500\n",
      "Iter:   65 | Cost: 89643606968638195807187559396071154905897212845357358882789753593463043467679525377577399845232376043586221267833119021568393862060707093808300661341642503234242518118865102179776799440896.0000000 | Accuracy: 0.3125000\n",
      "Iter:   66 | Cost: 75213925266459937080759010800376260700018449144536902649597304782321239978735716694169103294722038460519043923437930462918398331406869782290688089373501945187083062800244867854063042228649984.0000000 | Accuracy: 0.3125000\n",
      "Iter:   67 | Cost: 63106949232506459563294761411684746519836799554505245539868363454201111718522950269136615633293315569380138690944232150402333999610060827016553439973916377967119757439206669118866903532308529152.0000000 | Accuracy: 0.6250000\n",
      "Iter:   68 | Cost: 52948799405501281880894844888838362940226278350804537881114329112284427992260969524575403412921742470373941346948676805923510029286884342843903388796719298706909314327872413623548249077618187436032.0000000 | Accuracy: 0.4687500\n",
      "Iter:   69 | Cost: 44425778659569280108682939103241222839866876409774770549826487958216306922739479908429036347599490117150915660584616168879399365475632860290490910133174080863928473240645838351688498308488240669130752.0000000 | Accuracy: 0.6250000\n",
      "Iter:   70 | Cost: 37274684821351801812949781651267265433616589089016739735858774895557252278892072024299212168337926699275227771188231093109595959748498284150906530105288856263195748748465992478510226088137712517091688448.0000000 | Accuracy: 0.5312500\n",
      "Iter:   71 | Cost: 31274682638158774045150170077013491975241099811275975703050073911664117426034818214744532147596737051496468086848727233215763010176709710569528615438352383011688851339679252148617984530647732454969701302272.0000000 | Accuracy: 0.6875000\n",
      "Iter:   72 | Cost: 26240484092766031070085820643322585810258395061150970720035675666485509062988173132288996609960757165290896022154090110396489930765598703668772754715697169928445349043437477787784162628810484456253728869056512.0000000 | Accuracy: 0.3750000\n",
      "Iter:   73 | Cost: 22016626463943075503599967198083414692553348774292862295286330968774720361668560741481319952752343216856524749319162695068679968483743056318282266611638709487432999353411183301698635862889360011898592493765132288.0000000 | Accuracy: 0.4687500\n",
      "Iter:   74 | Cost: 18472671431638306603582930979933182692261482997266229875998869486903508237808993541266760026656956980243023648488656884515171468117500965111188977288549995718491787453920516055384787640992623780268612555376756260864.0000000 | Accuracy: 0.5000000\n",
      "Iter:   75 | Cost: 15499176968829408340144652347028807634325782776873617782205216224817390281319611104868740979384439121525498796555104299619772853476557560963715543339897265573270279940796938413170980468744902687182826414296029171023872.0000000 | Accuracy: 0.4375000\n",
      "Iter:   76 | Cost: 13004317626721674401626979321343629951105347674340228314711879443748054644497101661178208812782258415950947284124319313467583481277111607509677119740320427764441429284183528530405706017953021005293525359456236421408358400.0000000 | Accuracy: 0.5312500\n",
      "Iter:   77 | Cost: 10911048843223602746057070502088578141223465755689575930867487789685589193163632442077045494238928331402737716546914583894112897503520072028550604457890044965427468929163551442432374646886311954298143737763306345700744232960.0000000 | Accuracy: 0.4375000\n",
      "Iter:   78 | Cost: 9154727704787951379679228135911298616392723946300782614023013051858706004889427631559020557850798275735172331521330405815548951740762752720071047634558592309919790938692732948734438710251229131272762939341729221328515316580352.0000000 | Accuracy: 0.3750000\n",
      "Iter:   79 | Cost: 7681116687591611857212238190615677528427459664924758892193633979383924141336457587806372473488041283663093796103643126334720813750542895645925372356435857462387773411822589408969851166801649283059655024176632528664924215018782720.0000000 | Accuracy: 0.5312500\n",
      "Iter:   80 | Cost: 6444708730937058037472021321128088226396515269158858580566651122769775291702957376543888111491749925913410162250667534757079765550876892212540295469011669441488507858473282799411366092511463253877144204441686704427655104315734884352.0000000 | Accuracy: 0.6875000\n",
      "Iter:   81 | Cost: 5407321918922605908657858397651446614361637723433224009193536564467963801789480556082574353528056259025829466242772018016212029518316431628158752837759608698579467846396071231124119040987512499834235512128001867342327795355206245416960.0000000 | Accuracy: 0.4062500\n",
      "Iter:   82 | Cost: 4536920372289589748701801359626394330760056735407809186005804092900840979134619747920975658225541092087416771629022989069722988544070128951827913849847984451097751614586011955486078129141407391614457677121440498389417246764286288794222592.0000000 | Accuracy: 0.5000000\n",
      "Iter:   83 | Cost: 3806624938024312608822778167173835956285144280526620703753879951131469815201800794659728604710280524131208028277010660445182764060203237965574174053905988060034010776240013789907656532700848174665825585502336033738266920179549160538065862656.0000000 | Accuracy: 0.5000000\n",
      "Iter:   84 | Cost: 3193883125499052126684623358331608978317091647623104291323974287454996554035865942852353059344377806117652316608360242787570187326420722278625755799178009276528858484790194706759257999371518316955330543155461605018486441431510349152741046091776.0000000 | Accuracy: 0.3750000\n",
      "Iter:   85 | Cost: 2679772655680126240042970045372733950138142606934753688784193533114079096234748740955114275270911334159094018283513762549562582628789935676108146697031142101326636534696504845418608998583556967544879941756081651105008317703480025781012653555056640.0000000 | Accuracy: 0.5312500\n",
      "Iter:   86 | Cost: 2248417116079924141432433687806338211580904301191810541029534647694242056485547406816225214925025670995991077645950759894070037544933802518536801675285145668617241702089211202688251906544576933741550527754376571660583234239472467354698862765323321344.0000000 | Accuracy: 0.4375000\n",
      "Iter:   87 | Cost: 1886495676103578282778251782286174261082183154050755194187997061113201328946260438025152931812763406103388200499943912918737886101566070910958886394754526710353928068589942997424360618390323560154335896640163327318972149604928896113765274551420803088384.0000000 | Accuracy: 0.4375000\n",
      "Iter:   88 | Cost: 1582831722150523501095597881887812374359646855808076785621998539884070060974616915689546419526658664537347356656933141752113361811077351721289896247866158777805344707617113255919898859253367779190534180492966375022190931676612350071630443178240067451748352.0000000 | Accuracy: 0.5000000\n",
      "Iter:   89 | Cost: 1328047708977856501162530105902319453672163145916250553681198475186138513262731069701086241640882156499361867295439510433841950411454304600598276025434546631827868526769026642305372137799343899820475404367875083136446913455685639575529823634548734050646884352.0000000 | Accuracy: 0.4375000\n",
      "Iter:   90 | Cost: 1114275568678305439764027530253935882574704161086496126590720513471588852091242133393830196135443831581345979571285185363680949109264981067012347012580342358479067937951358531563862871843910579320233796700224729751400934433201663697997719330622786025561234866176.0000000 | Accuracy: 0.5312500\n",
      "Iter:   91 | Cost: 934913734318305269033579454372544138812164026053885378494780885088460575204501793606752848655200548157025384378374386910803976202254222143258382360385157114445664674865922318864106807499653151799397339931488937841185169679905520091033012959439304289941831328727040.0000000 | Accuracy: 0.6250000\n",
      "Iter:   92 | Cost: 784423274804245708454585350576944253247825152380248889482576402931880976516107378566071357084317309730329637465742652103744328023823204919598530453372069994006676323714423949016368035037512124497176463649569766940333911928162736692566532839187983104660314870029221888.0000000 | Accuracy: 0.5625000\n",
      "Iter:   93 | Cost: 658156845351382983299716602011286419596568011701687397824019067747953163728474262470472698295313903367985555746585991414761429557902887166574537302479326749736349846615631161972074709714140526287203825227765012141939244613720181353867048651164924353392894681515932254208.0000000 | Accuracy: 0.5937500\n",
      "Iter:   94 | Cost: 552215171319315280943182722058829854917516343959985685657511126276665860819876027081213471670809470853891643933322500078501501400017691358245649254402436266762850728406480588882048417996600276095804163918434292194169775125931902537189307520919222438301733960420815093628928.0000000 | Accuracy: 0.4062500\n",
      "Iter:   95 | Cost: 463326633444669835690662374014546315353386117728322091413457592301523620043471234473301086531156012101005389275670316638518780412300179173301337354106682785352218689521778106585152004708597006861989637947121993494395437630291413592317818352155518810867112195295002320978313216.0000000 | Accuracy: 0.4687500\n",
      "Iter:   96 | Cost: 388746235903466614073752563340178170874742665284934391896860424108138983134589297741547331186141083687179881408501464093766589913310501927213962413904481599620266326663668446515541228476142664985912299565843293254318521113394578070605910301969522197247074077949813291523451650048.0000000 | Accuracy: 0.4375000\n",
      "Iter:   97 | Cost: 326170837203038745361190727025608548193208475601962296906531682374338606300507028525646639579431835098087704705402667004654991217493498919715958017278574344285655233674142262394323374602141880132289862925073979524866063930238549230060678105139526735246325704183499541625345429995520.0000000 | Accuracy: 0.4687500\n",
      "Iter:   98 | Cost: 273668026121156591600398492456946457283372622018897744157342071872883358772401089302969342145555339801142966005271756326908372615686449029242724143381472442261146601161768690373636755412768029271982409402688735305734773600882210216545464414264092776140420046126044432738219405476888576.0000000 | Accuracy: 0.5937500\n",
      "Iter:   99 | Cost: 229616446287100595861523945015708637140030550695041883484409336692151596515677245691915217509307116751721763793852782960540196504316641566956707631491876736464010839578107252338865782822532433562010456929816905135054352064259082365793328213942435214634895517594365820041432970786836054016.0000000 | Accuracy: 0.5312500\n",
      "Iter:  100 | Cost: 192655726548688492163943315741262046259273305056656831624374967425428588539955152199737285031973700740512715728299109738916993413170401934749973306794725593052535932827785974045364564106962427955782598111625857398655083583157581273779402552686634895079573167442956688715253737807981492305920.0000000 | Accuracy: 0.5312500\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "# fetch dataset\n",
    "ionosphere = fetch_ucirepo(id=52)\n",
    "# data (as pandas dataframes)\n",
    "X = ionosphere.data.features\n",
    "y = ionosphere.data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_dropped = X.drop(X.columns[[0, 1]], axis=1)\n",
    "print('Shape:',X_dropped.shape[1])\n",
    "y_change = y.replace({'g': 1, 'b': -1})\n",
    "# Normalize each row in X\n",
    "# Convert DataFrame to numpy array\n",
    "X_array = X_dropped.to_numpy()\n",
    "# Calculate the normalization factor for each row\n",
    "normalization = np.sqrt(np.sum(X_array**2, axis=-1))\n",
    "X_norm_array = (X_array.T / normalization).T\n",
    "X_norm_array\n",
    "Y_train = y.to_numpy()\n",
    "from sklearn.model_selection import train_test_split\n",
    "# First, split into training + validation and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_norm_array, Y_train, test_size=0.2, shuffle=True, random_state=42)\n",
    "arrays = [Y_train, Y_test]\n",
    "names = [\"Y_train\", \"Y_test\"]\n",
    "\n",
    "for y, name in zip(arrays, names):\n",
    "    values, counts = np.unique(y, return_counts=True)\n",
    "    print(f\"{name}: Values: {values} Counts: {counts}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from modules.Ansatz import circuit\n",
    "from modules.metrics import accuracy\n",
    "import pennylane as qml\n",
    "import pennylane.numpy as np\n",
    "X_val=X_test\n",
    "Y_val=Y_test\n",
    "num_qubits = 5\n",
    "num_layers = 6\n",
    "\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "learning_rate = 0.01\n",
    "batch_size = 5\n",
    "num_epochs = 60\n",
    "state_prep='Mottonen'\n",
    "# train the variational classifier\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "\n",
    "# params = circuit_training(X_train,Y_train,X_test, Y_test,num_qubits, num_layers,bias_init,learning_rate,batch_size, num_epochs,state_prep='Mottonen',seed = 0)\n",
    "all_accuracy = []\n",
    "\n",
    "opt = qml.NesterovMomentumOptimizer(stepsize=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Update the weights by one optimizer step, using only a limited batch of data\n",
    "    batch_index = np.random.randint(0, len(X_train), (batch_size,))\n",
    "    X_batch = X_train[batch_index]\n",
    "    Y_batch = Y_train[batch_index]\n",
    "    weights, bias = opt.step(cost, weights, bias, X=X_batch, Y=Y_batch, num_qubits=num_qubits, state_prep=state_prep)\n",
    "\n",
    "    # Compute predictions on train and validation set\n",
    "    predictions_train = [np.sign(variational_classifier(weights, bias, x, num_qubits, state_prep)) for x in X_batch]\n",
    "\n",
    "    predictions_val = [np.sign(variational_classifier(weights, bias, x, num_qubits, state_prep)) for x in X_val]\n",
    "    current_cost = cost(weights, bias, X_batch, Y_batch, num_qubits, state_prep)\n",
    "\n",
    "    # Compute accuracy on train and validation set\n",
    "    print(Y_batch[0],'   ',predictions_train[0])\n",
    "    acc_train = accuracy(Y_batch, predictions_train)\n",
    "    acc_val = accuracy(Y_val, predictions_val)\n",
    "\n",
    "    print(f\"Epoch: {epoch} | Cost: {current_cost:0.7f} | \"f\"Acc train: {acc_train:0.7f} | Acc validation: {acc_val:0.7f}\"\n",
    "          )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}